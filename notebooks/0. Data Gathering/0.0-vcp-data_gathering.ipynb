{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data to be used in this work come from kaggle competition [Ashrae - Great Energy Predictor III](https://www.kaggle.com/c/ashrae-energy-prediction), where the goal is to predict the energy consumption in several buildings around different locations for the next two years. These are the files:\n",
    "\n",
    "\n",
    "**train.csv**\n",
    "* `building_id` - Foreign key for the building metadata.\n",
    "* `meter` - The meter id code. Read as `{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}`. Not every building has all meter types.\n",
    "* `timestamp`  - When the measurement was taken\n",
    "* `meter_reading` - The target variable. Energy consumption in kWh (or equivalent). Note that this is real data with measurement error, which we expect will impose a baseline level of modeling error.\n",
    "\n",
    "**building_meta.csv**\n",
    "* `site_id` - Foreign key for the weather files.\n",
    "* `building_id` - Foreign key for training.csv\n",
    "* `primary_use` - Indicator of the primary category of activities for the building based on EnergyStar property type definitions\n",
    "* `square_feet` - Gross floor area of the building\n",
    "* `year_built` - Year building was opened\n",
    "* `floor_count` - Number of floors of the building\n",
    "\n",
    "**weather_[train/test].csv**\n",
    "\n",
    "Weather data from a meteorological station as close as possible to the site.\n",
    "\n",
    "* `site_id`\n",
    "* `air_temperature` - Degrees Celsius\n",
    "* `cloud_coverage` - Portion of the sky covered in clouds, in oktas\n",
    "* `dew_temperature` - Degrees Celsius\n",
    "* `precip_depth_1_hr` - Millimeters\n",
    "* `sea_level_pressure` - Millibar/hectopascals\n",
    "* `wind_direction` - Compass direction (0-360)\n",
    "* `wind_speed` - Meters per second\n",
    "\n",
    "**test.csv**\n",
    "\n",
    "The submission files use row numbers for ID codes in order to save space on the file uploads. test.csv has no feature data; it exists so you can get your predictions into the correct order.\n",
    "\n",
    "* `row_id` - Row id for your submission file\n",
    "* `building_id` - Building id code\n",
    "* `meter` - The meter id code\n",
    "* `timestamp` - Timestamps for the test data period\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pourpose of this Master Thesis, we will initialy only consider and perform the analysis and modeling for one location. We need to import the very raw data first and perform a slight first exploratory analysis in order to choose the site. We'll look for the site with the highest level of data quality, trying to avoid as far as possible missing values, inconsistencies, etc., since the aim of this work is much about aplying several ML algorithms, rather than cleaning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load libraries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import gc\n",
    "from src.functions import data_import as dimp\n",
    "from src.functions import data_exploration as dexp\n",
    "import pandas_profiling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\n",
    "In order to avoid memory problems because of the size of the data sets, we're using the funciton `import_data` from our local library `utils`, that considerably reduces the size of data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dimp.import_data('../../data/raw/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "building_meta = dimp.import_data('../../data/raw/building_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 9.60 MB\n",
      "Memory usage after optimization is: 2.65 MB\n",
      "Decreased by 72.4%\n"
     ]
    }
   ],
   "source": [
    "weather_train = dimp.import_data('../../data/raw/weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test = dimp.import_data('../../data/raw/weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dimp.import_data('../../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import data\n",
    "dimp.load_data('../../data/raw/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the library `pandas_profiling` for some data sets (those with shortest size) to get a report with a general exploratory data analysis that we'll use to decide the site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set `weather_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable `timestamp` is categorical. Let's convert it to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train['timestamp'] = pd.to_datetime(weather_train['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reports by `site_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = weather_train['site_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_reports = dexp.export_reports(weather_train, sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.name = 'wather_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexp.export_reports(weather_train, weather_train_reports, '../../data/external/weather_train_profiles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set `weather_test` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`timestamp` is categorical, let's convert it to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test['timestamp'] = pd.to_datetime(weather_test['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reports by `site_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test.name = 'weather_test'\n",
    "weather_test_reports = dexp.get_report_by_site(weather_test, weather_test['site_id'].unique())\n",
    "dexp.export_reports(weather_test, weather_test_reports, '../../data/external/weather_test_profiles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set `building_metadata` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features `year_built` and `floor_count`  are `float` type. We're casting it to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta_df['year_built'] = pd.array(building_meta_df['year_built'], dtype=pd.Int32Dtype())\n",
    "building_meta_df['floor_count'] = pd.array(building_meta_df['floor_count'], dtype=pd.Int32Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reports by `site_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_meta.name = 'building_metada'\n",
    "building_meta_reports = dexp.get_report_by_site(building_meta, building_meta['site_id'].unique())\n",
    "dexp.export_reports(building_meta, building_meta_reports, '../../data/external/building_meta_profiles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train` data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the data sets profile, the decision is to select `site_id 1` location. In the following lines, we're selecting the rows of each data set for this location and exporting the resulting data frames to `csv` files. We will use those files as our starting data sets for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train[weather_train['site_id']==1].to_csv('../../data/interim/site_1/weather_train.csv', index=False)\n",
    "weather_test[weather_test['site_id']==1].to_csv('../../data/interim/site_1/weather_test.csv', index=False)\n",
    "building_meta[building_meta['site_id']==1].to_csv('../../data/interim/site_1/building_metada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no `site_id` foreign key in `train` set, the key is `building_id` so we need to extract all the the rows where the `building_id` is in the building ids list for site 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_site_1 = list(building_meta.loc[building_meta['site_id']==1, 'building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_site_1 = train[train['building_id']==buildings_site_1[0]]\n",
    "\n",
    "for i in range(1,len(buildings_site_1)):\n",
    "    train_site_1 = train_site_1.append(train[train['building_id']==buildings_site_1[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_site_1.to_csv('../../data/interim/site_1/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(weather_train, building_meta, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `test` set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_site_1 = test[test['building_id']==buildings_site_1[0]]\n",
    "\n",
    "for i in range(1,len(buildings_site_1)):\n",
    "    test_site_1 = test_site_1.append(test[test['building_id']==buildings_site_1[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_site_1.to_csv('../../data/interime/site_1/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
